extern crate regex;
use regex::Regex;
use std::collections::{HashMap,HashSet};
// hand-build a lexer

pub enum Token
{
   Integer(i64),
   Float(f64),
   Symbol(String),
   Alphanum(String),
   Keyword(String),
   Stringlit(String),
   Verbatim(String),
}

pub struct Tokenizer
{
  int_re : Regex,  // to be generated from re_str
  float_re : Regex,
  sym_re : Regex,
  alpha_re : Regex,
  kw_re    : Regex,
  str_re   : Regex,
  verb_re  : Regex,
  pub keywords: String,
  pub symbols: String,
}
impl Tokenizer
{
/*
   fn new() -> Tokenizer
   {  Tokenizer::default() }
*/  
   fn addkeyword(&mut self, kw:&str)
   {  self.keywords.push('|');
      self.keywords.push_str(kw);
      self.kw_re = Regex::new(&self.keywords).unwrap();
   }
   fn addsymbol(&mut self, sym:&str)
   {
    if sym.len()>1 {
      self.symbols.push('|');
      self.symbols.push_str(sym);
      self.sym_re = Regex::new(&self.symbols).unwrap();
     }
   }
}//impl tokenizer
/*
impl Default for Tokenizer
{
  fn default() -> Self
  {
     let keywords = "if|while|else|let|lambda|for";

     let symbols = "== <= >= != :: && || -->";
     let mut kv:Vec<String> = Vec::new();
     for k in kws.split_whitespace() { kv.push(String::from(k)); }
     let mut mv:Vec<String> = Vec::new();
     for k in mssyms.split_whitespace() { mv.push(String::from(k)); }     
     Tokenizer {
        split_re: Regex::new(r"\*|\s|[-/=.]").unwrap(),
        keywords: kv,
        multicharsyms : mv,
     }
  }
}//impl Default
*/
pub fn mymain()
{
  let input ="abc=123-4*5/1.6 ok [--]";
  let split_re = Regex::new(r"\*|\s|[-/=.]").unwrap();
  let split = split_re.split(input).into_iter();
  for x in split { println!("({})",x); }
}//main
